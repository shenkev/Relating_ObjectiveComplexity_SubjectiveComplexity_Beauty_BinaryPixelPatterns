sha,filename,url,lines,title,comment,priority,category,additional,id,private
"e4ac40563dfade21ced05cf94d46d72c164830af","/scripts/DescriptiveAnalysis.py","","47:0-55:0","Add reference to math","Maybe add a reference to the math for computing the lower and upper bounds. It makes checking correctness easier and you may need to refer to it at a later point in time.","0","Maintainability","","1e78e25c-da51-4ead-ba1e-ba65dafefbb3","0"
"e4ac40563dfade21ced05cf94d46d72c164830af","/scripts/DescriptiveAnalysis.py","","212:0-214:0","Variable names too long","I would call it df_patternmean for example.","0","Best Practices","","d28b7339-8ad8-4e54-bf91-07bf0afc19da","0"
"e4ac40563dfade21ced05cf94d46d72c164830af","/scripts/DescriptiveAnalysis.py","","216:0-219:0","Lines too long, hard to read","The first line is hard to parse. Part of the problem is the long variable name. But you could also split up this line into more smaller lines with intermediate variables.\n\nIt might be clearer if you used a percentile function and got the value at 33, 66 percentiles. Also there might be a function in pandas that does this binning for you.","0","Code-Style","","8afaed70-9f5a-4472-847a-687feb8606cc","0"
"e4ac40563dfade21ced05cf94d46d72c164830af","/scripts/DescriptiveAnalysis.py","","221:0-228:0","Just make new columns with pandas","You can avoid the .apply here by simply making the ""full symmetry"" and ""unidirection symmetry"" columns in the dataframe.","0","Best Practices","","75cc8853-26c9-4893-9f8c-429e134449fe","0"
"e4ac40563dfade21ced05cf94d46d72c164830af","/scripts/DescriptiveAnalysis.py","","230:0-246:0","Separate plotting code from data processing code","This block is in the same cell as the block above. I would separate the plotting code into a different cell in jupyter noteobook.","0","Code-Style","","940160ed-002c-4ad7-82c7-8423a86cfc05","0"
"e4ac40563dfade21ced05cf94d46d72c164830af","/scripts/DescriptiveAnalysis.py","","256:0-262:0","Do you need to shuffle the train and test split?","Are there any biases to using the first 40 rows for testing? Do you need to shuffle the test and train rows?","0","Reliability","","20ba6792-6143-4bbc-a6dd-8454d5267afe","0"
"439e8d79198575f9386a9b049829eb228cab1626","/measures/quadtree/calculate_quadtree.py","","47:71-47:85","len(np.arange(0,grid_size_rows//2))","Why len(np.arange(0,grid_size_rows//2))?\n\nCan't you do simply set the length to (grid_size_rows//2-0)?","0","Code-Style","","65abedbd-2b4c-47d7-8570-0086c028a56a","0"
"439e8d79198575f9386a9b049829eb228cab1626","/measures/local spatial complexity/calculate_local_spatial_complexity.py","","93:0-94:0","""pattern"" vs ""grid""","The grid argument is called ""grid"" in other metric files. It helps to be consistent. Then pattern.copy() could be named ""grid_copy""","0","Best Practices","","8d9fa311-9bc7-4ddb-8b3e-7e38ac4e724a","0"
"439e8d79198575f9386a9b049829eb228cab1626","/measures/local spatial complexity/calculate_local_spatial_complexity.py","","147:0-151:0","Where do these test values come from?","Why did you get the test values/true outputs of the function to test against? Is that source reliable?","0","Reliability","","35f5f8fa-627c-4d18-8bff-76bcc3664763","0"
"439e8d79198575f9386a9b049829eb228cab1626","/measures/local spatial complexity/calculate_local_spatial_complexity.py","","27:0-76:0","Break into a helper function","This should be a helper function to increase readability of the code.","0","Best Practices","","dbb78ec6-3054-486a-84bd-a7c670fd722a","0"
"439e8d79198575f9386a9b049829eb228cab1626","/measures/local spatial complexity/calculate_local_spatial_complexity.py","","29:5-32:23","Simplify the logic","Perhaps you can use a dictionary to map from dirn --> (i', j') so that you can simply write,\n\n\nif grid_size > i' > 0 and grid_size > j' > 0: \n  if grid[i', j'] == col2:\n    count_neigh += 1\n  if grid[i, j] == col1 and grid[i', j'] == col2:\n    count_tuples += 1","0","Complexity","","a885d30b-1021-4199-b023-337cd49e95cd","0"
"439e8d79198575f9386a9b049829eb228cab1626","/measures/local spatial complexity/calculate_local_spatial_complexity.py","","138:0-142:0","Stronger/more interesting test case","Perhaps a stronger test case is required here. These 4 patterns don't test local spatial complexity very extensively.","0","Reliability","","bcbeebf9-ea90-468e-b16f-f104636f4aeb","0"
"439e8d79198575f9386a9b049829eb228cab1626","/measures/intricacy/calculate_intricacy.py","","112:0-118:0","Helper function","You should put this code into a helper function ""initialize_graph()"" or ""initialize_graph_edges()"" for readability. You'd call the function twice, once for 4-n and once for 8-n which means the code is slower but readability is more important since the code is very fast anyway for your grid sizes.","0","Best Practices","","6f9f725a-d3ca-49fe-acd6-ac94c70aaa1d","0"
"439e8d79198575f9386a9b049829eb228cab1626","/measures/entropy_of_means/calculate_entropy_of_means.py","","30:0-42:0","Why use a third party implementation?","Why use the stackexchange solution? If I understand the metric correctly, I think you need 2 functions:\n- smooth() which could use a convolution to smooth the grid\n- entropy() which takes the smoothed grid and computes the entropy with sum over p*logp","0","Reliability","","861a5ddb-d69e-4b33-a540-871b840f068c","0"
